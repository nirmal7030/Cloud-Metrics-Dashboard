name: Test & Deploy Cloud Metrics Dashboard to AWS EC2

on:
  push:
    branches: ["main"]

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  ECR_REPOSITORY: cloud-metrics-dashboard
  IMAGE_TAG: latest

jobs:
  test:
    name: Stage 1 - Build & Test
    runs-on: ubuntu-latest

    # Expose durations so deploy job can use them
    outputs:
      build_duration: ${{ steps.build_step.outputs.build_duration }}
      test_duration:  ${{ steps.test_step.outputs.test_duration }}

    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      # â±ï¸ Timed dependency install ("build" time)
      - name: Install dependencies (timed)
        id: build_step
        run: |
          set -e
          START=$(date +%s)
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          END=$(date +%s)
          echo "build_duration=$((END-START))" >> "$GITHUB_OUTPUT"

      # â±ï¸ Timed tests
      - name: Run Django tests (timed)
        id: test_step
        run: |
          set -e
          START=$(date +%s)
          python manage.py test
          END=$(date +%s)
          echo "test_duration=$((END-START))" >> "$GITHUB_OUTPUT"

  deploy:
    name: Stage 2 - Deploy to EC2
    needs: test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push Docker image to ECR
        run: |
          set -e
          docker build -t $ECR_REPOSITORY:$IMAGE_TAG .
          docker tag  $ECR_REPOSITORY:$IMAGE_TAG ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:$IMAGE_TAG
          docker push ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:$IMAGE_TAG

      - name: Deploy on EC2 (Docker run)
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ubuntu
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            set -e

            REGISTRY="${{ steps.login-ecr.outputs.registry }}"
            IMAGE="$REGISTRY/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}"

            echo "Using image: $IMAGE"

            # Stop & remove old container if it exists
            sudo docker stop metrics-bench || true
            sudo docker rm   metrics-bench || true

            # Login to ECR from EC2
            aws ecr get-login-password --region ${{ env.AWS_REGION }} \
              | sudo docker login --username AWS --password-stdin "$REGISTRY"

            # Pull latest image and run container with BENCH_API_KEY env
            sudo docker pull "$IMAGE"
            sudo docker run -d -p 80:8000 --name metrics-bench \
              -e BENCH_API_KEY=${{ secrets.BENCH_API_KEY }} \
              "$IMAGE"

      # ðŸŒ Post live novel metrics to your Django API **from inside EC2**
      - name: Post novel metrics to app (from EC2)
        uses: appleboy/ssh-action@v0.1.7
        env:
          BENCH_API_KEY: ${{ secrets.BENCH_API_KEY }}
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ubuntu
          key: ${{ secrets.EC2_SSH_KEY }}
          # pass BENCH_API_KEY through to the remote environment
          envs: BENCH_API_KEY
          script: |
            set -e

            # Durations from Stage 1 (GitHub will substitute these values)
            BUILD_DUR=${{ needs.test.outputs.build_duration || '0' }}
            TEST_DUR=${{ needs.test.outputs.test_duration  || '0' }}

            echo "BUILD_DUR=$BUILD_DUR"
            echo "TEST_DUR=$TEST_DUR"

            # ----- derive novel metrics (same style as original workflow) -----
            # LCE (Layer Cache Efficiency) â€“ higher for faster builds
            LCE=$(( 100 - BUILD_DUR / 2 ))
            if [ "$LCE" -lt 0 ]; then LCE=0; fi
            if [ "$LCE" -gt 100 ]; then LCE=100; fi

            # PRT (Pipeline Recovery Time) â€“ here approximated with test duration
            PRT=$TEST_DUR

            # SMO (Secrets Management Overhead) â€“ constant placeholder
            SMO=1

            # DEPT (Dynamic Env Provisioning Time) â€“ tie to test duration
            DEPT=$TEST_DUR

            # CLBC (Cross-Layer Build Consistency) â€“ 100 for successful pipeline
            CLBC=100

            # Optional overall score
            VALUE=$(( (LCE + CLBC) / 2 ))

            cat > payload.json <<EOF
            {
              "source": "github",
              "workflow": "Test & Deploy Cloud Metrics Dashboard to AWS EC2",
              "run_id": "$(date +%s)",
              "run_attempt": "1",
              "branch": "main",
              "commit_sha": "local-ssh",

              "lce":  $LCE,
              "prt":  $PRT,
              "smo":  $SMO,
              "dept": $DEPT,
              "clbc": $CLBC,

              "value": $VALUE,
              "notes": "auto-ingest of novel metrics from CI (via EC2 ssh)"
            }
            EOF

            echo "Payload to send:"
            cat payload.json

            # Call the Django app from EC2 itself
            curl -f -sS -X POST "http://localhost/api/metrics/ingest/" \
              -H "Content-Type: application/json" \
              -H "X-Bench-Key: $BENCH_API_KEY" \
              --data @payload.json

            echo "Metrics posted successfully."
